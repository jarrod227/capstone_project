# Data Flow — System Pipeline

## Overview

All 9 run configurations (3 sources × 3 modes) share the same data source layer. Signal processing usage differs by mode.

```
┌─────────────────────────────────────────────────────────┐
│                     DATA SOURCE                         │
│                                                         │
│   --replay csv          --simulate         --port COM4   │
│   CSVReplaySource      HardwareSimulator   SerialReader  │
│   (csv_replay.py)       (simulator.py)  (serial_reader.py)│
└────────────────────────┬────────────────────────────────┘
                         │
                         │  SensorPacket (eog_v, eog_h, gyro_x, gyro_y, gyro_z)
                         │
            ┌────────────┼──────────────────────┐
            │            │                      │
            ▼            ▼                      ▼
    ┌──────────┐  ┌────────────┐  ┌───────────────────────┐
    │threshold │  │ statespace │  │         ml            │
    │  mode    │  │   mode     │  │                       │
    │          │  │            │  │  raw EOG (both ch)    │
    │ lowpass  │  │ lowpass    │  │  SlidingWindow (200)  │
    │ EOG      │  │ EOG        │  │  EOGClassifier (SVM)  │
    │ +deadzone│  │ +state-    │  │  +deadzone (inside    │
    │ (inside  │  │  space     │  │   StateSpaceController│
    │controller│  │  model     │  │   for cursor only)    │
    │)         │  │            │  │                       │
    └────┬─────┘  └─────┬──────┘  └───────────┬───────────┘
         │              │                     │
         ▼              ▼                     ▼
                  pyautogui (OS mouse/keyboard API)
```

## Data Source Details

### CSVReplaySource (`--replay`)

```
main.py --replay ../data/raw/demo_replay.csv
    │
    └─→ imports CSVReplaySource (csv_replay.py)
            │
            │  Reads pre-generated CSV line by line
            │  Generated by: python -m scripts.generate_demo_data
            │  Columns: timestamp,eog_v,eog_h,gyro_x,gyro_y,gyro_z,label
            │
            └─→ yields SensorPacket(eog_v, eog_h, gyro_x, gyro_y, gyro_z)
```

### HardwareSimulator (`--simulate`)

```
main.py --simulate
    │
    └─→ imports HardwareSimulator (simulator.py)
            │
            ├─→ Generates packets at 200Hz continuously
            │     Keypresses change internal state; data streams regardless
            │
            ├─→ Key mapping
            │     Arrow keys → head motion (gyro_x/gyro_y)
            │     Space → blink spike, N → head nod
            │     U/D/L/R → gaze shifts (eog_v/eog_h)
            │
            └─→ yields SensorPacket(eog_v, eog_h, gyro_x, gyro_y, gyro_z)
```

### SerialReader (`--port`)

```
main.py --port COM4
    │
    └─→ imports SerialReader (serial_reader.py)
            │
            │  Reads from hardware MCU (STM32/Arduino)
            │  UART @ 115200 baud
            │  Format: "timestamp,eog_v,eog_h,gyro_x,gyro_y,gyro_z\r\n"
            │
            └─→ yields SensorPacket(eog_v, eog_h, gyro_x, gyro_y, gyro_z)
```

## Mode Details

Each mode function in `main.py` iterates over `source.stream()` and unpacks `SensorPacket` fields, but the controller and loop structure differ:

| Mode | Controller | EOG handling |
|------|-----------|--------------|
| threshold | `ThresholdController` | Low-pass filtered eog_v/eog_h → event detectors |
| statespace | `StateSpaceController` | Low-pass filtered eog_v/eog_h → event detectors |
| ml | `StateSpaceController` (cursor + nod via cursor_frozen_override, EOG=baseline) | Raw eog_v/eog_h → `EOGClassifier.predict()` + inline fusion (no filtering — must match training data) |

### Threshold Mode

```
main.py ─→ EOGLowPassFilter (signal_processing.py)
               │  eog_v, eog_h → 30Hz low-pass (preserves DC baseline)
               ▼
           ThresholdController (cursor_control.py)
               │
               ├─→ Inline deadzone (cursor_control.py)
               │     if |gy| > GYRO_DEADZONE: dx = gy * sensitivity
               │     if |gx| > GYRO_DEADZONE: dy = gx * sensitivity
               │
               ├─→ BlinkDetector (event_detector.py)
               │     eog_v → DOUBLE_BLINK → left click
               │     eog_v → TRIPLE_BLINK → double click
               │     eog_v → LONG_BLINK   → right click
               │
               ├─→ GazeDetector (event_detector.py)
               │     eog_v + gx fusion → scroll up/down
               │
               ├─→ HorizontalGazeDetector (event_detector.py)
               │     eog_h + gy fusion → browser back/forward
               │
               └─→ DoubleNodDetector (event_detector.py)
                     gx → center cursor (two quick nods)
                     ⚡ Only active when cursor_frozen (looking left/right)
                                │
                                ▼
                          pyautogui (OS mouse/keyboard API)
```

**Cursor freeze mechanic:** Looking left or right (eog_h beyond threshold) freezes the cursor. The double nod detector is only active while the cursor is frozen — this prevents accidental triggers during normal head movement and eliminates cursor drift during gestures.

**Files:** `main.py` → `config.py` → `signal_processing.py` → `cursor_control.py` → `event_detector.py`

### State-Space Mode

```
main.py ─→ EOGLowPassFilter (signal_processing.py)
               │  eog_v, eog_h → 30Hz low-pass (preserves DC baseline)
               ▼
           StateSpaceController (cursor_control.py)
               │
               ├─→ State-Space Model (cursor_control.py)
               │     gx/gy → inline deadzone → u[k]
               │     x[k+1] = A·x[k] + B·u[k]
               │     velocity → position (with velocity retention)
               │     See: docs/state_space.md
               │
               ├─→ BlinkDetector (event_detector.py)
               │     eog_v → DOUBLE_BLINK → left click
               │     eog_v → TRIPLE_BLINK → double click
               │     eog_v → LONG_BLINK   → right click
               │
               ├─→ GazeDetector (event_detector.py)
               │     eog_v + gx fusion → scroll up/down
               │
               ├─→ HorizontalGazeDetector (event_detector.py)
               │     eog_h + gy fusion → browser back/forward
               │
               └─→ DoubleNodDetector (event_detector.py)
                     gx → center cursor (two quick nods)
                     ⚡ Only active when cursor_frozen (looking left/right)
                                │
                                ▼
                          pyautogui (OS mouse/keyboard API)
```

**Files:** `main.py` → `config.py` → `signal_processing.py` → `cursor_control.py` → `event_detector.py`

**Difference from threshold:** Cursor movement uses state-space physics model (inertia + velocity decay) instead of direct proportional mapping. All event detectors are identical.

### ML Mode

```
main.py ─→ run_ml_mode() (main.py)
               │
               ├─→ EOGClassifier (ml_classifier.py)
               │     raw eog_v + raw eog_h (no filtering — must match training data)
               │     │
               │     ├─→ SlidingWindow (signal_processing.py)
               │     │     200-sample dual-channel buffer
               │     │
               │     ├─→ extract_dual_features() (feature_extraction.py)
               │     │     20 features (peak_amp, zero_cross, slope, max_deriv,
               │     │       mean, std, skew, kurt, rms, deriv_var) × 2 ch
               │     │
               │     ├─→ eog_scaler.pkl (StandardScaler)
               │     │     normalize features
               │     │
               │     └─→ eog_model.pkl (SVM classifier)
               │           predict: idle / blink / double_blink /
               │                    triple_blink / long_blink / look_up /
               │                    look_down / look_left / look_right
               │           (blink = single blink, trained but no action)
               │
               ├─→ Sensor Fusion (in main.py)
               │     prediction + gx/gy inline deadzone check
               │     look_up + gx < -deadzone  → scroll up
               │     look_down + gx > deadzone → scroll down
               │     look_left + gy < -deadzone → browser back
               │     look_right + gy > deadzone → browser forward
               │     double_blink → left click (no fusion needed)
               │     triple_blink → double click (no fusion needed)
               │     long_blink → right click (no fusion needed)
               │
               └─→ StateSpaceController (cursor_control.py)
                     eog_v=EOG_BASELINE, eog_h=EOG_BASELINE
                     (all EOG classification handled by ML above)
                     gyro_x/gyro_y → inline deadzone → state-space → cursor
                     cursor_frozen_override=True when ML predicts look_left/look_right
                     → enables DoubleNodDetector inside controller
                                │
                                ▼
                          pyautogui (OS mouse/keyboard API)
```

**Files:** `main.py` → `config.py` → `signal_processing.py` → `ml_classifier.py` → `feature_extraction.py` → `cursor_control.py` → `models/eog_model.pkl` + `models/eog_scaler.pkl`

**Difference from threshold/statespace:** Uses SVM classifier instead of event detectors for EOG classification. Sensor fusion for scroll/navigation is done inline in `main.py` rather than in event_detector.py. When ML detects horizontal gaze, `cursor_frozen_override=True` is passed to the controller so that the double nod gesture works while the cursor is frozen.

## ML Training Pipeline (Offline)

Two data sources feed into the same training pipeline:

### Path A: Synthetic Data (no hardware needed)

```
scripts/generate_demo_data.py
    │
    │  Generates 3 training CSVs + 1 held-out replay CSV
    │  ~50% eye-only, ~50% eye+head correlated motion
    ▼
data/raw/demo_session_00.csv   ← training
data/raw/demo_session_01.csv   ← training
data/raw/demo_session_02.csv   ← training
data/raw/demo_replay.csv       ← held out (for --replay demo only)
```

### Path B: Real Hardware Data

```
scripts/collect_data.py --port COM4
    │
    │  Reads live sensor data via SerialReader (serial_reader.py)
    │  User labels events in real time with keyboard:
    │    0=idle  1=blink  2=double_blink  3=triple_blink
    │    4=long_blink  5=up  6=down  7=left  8=right
    │  Press ESC to stop and save
    ▼
data/raw/eog_session_<timestamp>.csv

# Cross-subject: use --output to name files per subject
scripts/collect_data.py --port COM4 --output ../data/raw/subject_A.csv
scripts/collect_data.py --port COM4 --output ../data/raw/subject_B.csv
```

### Training (same for both paths)

> **Note:** `train_model.py` loads all CSVs in the target directory **except** `demo_replay.csv` (held out for testing). If training with real hardware data, remove synthetic files first: `rm data/raw/demo_session_*.csv`

```
data/raw/*.csv
    │
    ▼
scripts/train_model.py --data ../data/raw
    │
    ├─→ Load CSVs → extract 20 features per window
    ├─→ StandardScaler fit + transform
    ├─→ SVM (RBF kernel) train + 5-fold CV
    │
    ▼
models/eog_model.pkl    (trained SVM)
models/eog_scaler.pkl   (fitted scaler)
```

## Firmware (STM32)

Data acquisition runs on STM32, developed with two ST tools:

- **STM32CubeMX** — graphical peripheral configuration tool. You select your STM32 chip, configure pins (ADC, I2C, UART, clocks) via a GUI, and it generates a `.ioc` project file plus HAL initialization code (`MX_ADC1_Init()`, `MX_I2C1_Init()`, etc.).
- **STM32CubeIDE** — Eclipse-based IDE for editing C code, compiling, and flashing. Opens the CubeMX-generated project and adds your application logic on top.

The **`.ioc` file** (`firmware/firmware.ioc`) is CubeMX's project file — it stores all peripheral assignments, clock tree settings, and pin configurations in XML format. The included `.ioc` is configured for STM32F303RETx (Nucleo-64). For a different board, create a new CubeMX project and configure the same peripherals.

```
firmware/firmware.ioc (CubeMX project file)
    │  Peripherals: ADC1 (PA0), ADC2 (PA4), I2C1, USART2 (115200 baud)
    │  Open in CubeMX → Generate Code → HAL initialization stubs
    ▼
STM32CubeIDE project
    │
    ├─→ firmware/Core/Src/main.c         # Main loop: read ADC×2 + I2C gyro, UART TX @200Hz
    ├─→ firmware/Core/Src/mpu9250.c      # MPU9250/MPU6050 I2C driver (gyro only)
    └─→ firmware/Core/Inc/mpu9250.h      # Driver header

    Main loop (5ms period):
      1. HAL_ADC_Start → read eog_v (PA0) + eog_h (PA4)
      2. MPU9250_ReadGyro → read gyro_x, gyro_y, gyro_z via I2C
      3. snprintf → "timestamp,eog_v,eog_h,gyro_x,gyro_y,gyro_z\r\n"
      4. HAL_UART_Transmit → USB serial to PC
```

**Setup workflow:** Open `firmware/firmware.ioc` in CubeMX (or create a new project for your board) → generate code → open in CubeIDE → drop in `main.c` and `mpu9250.c` → build and flash.

## File Reference

| File | Role |
|------|------|
| `main.py` | Entry point, argument parsing, ML mode loop |
| `eog_cursor/config.py` | All thresholds, paths, and tuning constants |
| `eog_cursor/serial_reader.py` | `SerialReader` (hardware UART) |
| `eog_cursor/simulator.py` | `HardwareSimulator` (keyboard-driven fake data) |
| `eog_cursor/csv_replay.py` | `CSVReplaySource` (offline CSV playback) |
| `eog_cursor/signal_processing.py` | `EOGLowPassFilter`, `GyroCalibrator`, `GyroKalmanFilter`, `GyroKalmanFilter3Axis`, `SlidingWindow` |
| `eog_cursor/feature_extraction.py` | `extract_features()`, `extract_dual_features()` |
| `eog_cursor/event_detector.py` | `BlinkDetector`, `GazeDetector`, `HorizontalGazeDetector`, `DoubleNodDetector` |
| `eog_cursor/cursor_control.py` | `ThresholdController`, `StateSpaceController` |
| `eog_cursor/keyboard_overlay.py` | `KeyboardOverlay` (keyboard-injected EOG events) |
| `eog_cursor/ml_classifier.py` | `EOGClassifier` (SVM wrapper) |
| `scripts/generate_demo_data.py` | Synthetic training data generator |
| `scripts/visualize.py` | Real-time 3-subplot signal visualization |
| `scripts/collect_data.py` | Real-time labeled data collection from hardware |
| `scripts/train_model.py` | SVM training + cross-validation |
| `firmware/Core/Src/main.c` | STM32 main loop: dual ADC + I2C gyro + UART TX @200Hz |
| `firmware/Core/Src/mpu9250.c` | MPU9250/MPU6050 I2C driver (gyro only) |
